{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "from typing import Optional, Callable, Tuple, Any\n",
    "\n",
    "class myCIFAR10(VisionDataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            only_noisy = True,\n",
    "            only_clean = False,\n",
    "            train_size = 0.7,\n",
    "    ) -> None:\n",
    "\n",
    "        super(myCIFAR10, self).__init__(root, transform=transform,\n",
    "                                      target_transform=target_transform)\n",
    "        \n",
    "        file_path = \"C:/Users/aakan/OneDrive/Documents/Spring 2022/Applied Data Science/GitHub/spring-2022-prj3-group1/data/\"\n",
    "\n",
    "        self.train = train  # training set or test set\n",
    "        \n",
    "        n_img = 50000\n",
    "        n_noisy = 40000\n",
    "        n_clean_noisy = n_img - n_noisy\n",
    "        imgs = np.empty((n_img,32,32,3))\n",
    "        for i in range(n_img):\n",
    "            img_fn = f'C:/Users/aakan/OneDrive/Documents/Spring 2022/Applied Data Science/GitHub/spring-2022-prj3-group1/data/images/{i+1:05d}.png'\n",
    "            imgs[i,:,:,:] = cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "            print(i,end=\"\\r\")\n",
    "\n",
    "        # load the labels\n",
    "        clean_labels = np.genfromtxt(file_path+'clean_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "        noisy_labels = np.genfromtxt(file_path+'noisy_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "        \n",
    "        # The class-label correspondence\n",
    "        self.classes = ('plane', 'car', 'bird', 'cat',\n",
    "                   'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        \n",
    "        if only_clean:\n",
    "            self.data = imgs[:n_clean_noisy]\n",
    "            self.targets = clean_labels\n",
    "            self.noisy_targets = noisy_labels[:n_clean_noisy]\n",
    "        else:\n",
    "            self.data = imgs\n",
    "            self.targets = noisy_labels\n",
    "        \n",
    "        random.seed(42)\n",
    "        \n",
    "        indexes = np.arange(len(self.data))\n",
    "        random.shuffle(indexes)\n",
    "        \n",
    "        if train:\n",
    "            self.data = self.data(indexes[:train_size*(len(indexes))])\n",
    "            self.targets = self.targets(indexes[:train_size*(len(indexes))])\n",
    "        else:\n",
    "            self.data = self.data(indexes[train_size*(len(indexes)):])\n",
    "            self.targets = self.targets(indexes[train_size*(len(indexes)):])\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        #img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f50da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd9cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232f042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
